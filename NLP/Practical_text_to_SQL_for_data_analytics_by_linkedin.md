تجربه Linkedin از Text-to-SQL

مساله اینه که خیلی از شرکت‌ها برای خودشون حجم زیادی داده دارند. داده‌هایی که در قالب یک سری جدول که خودشون شامل یک‌سری فیلد هستند ذخیره شده. کوئری زدن روی این داده‌ها حالا یکی از نیازمندی‌های پرتکرار و مهم برای هر شرکتی و کارمندانشه. نیازمندی که معمولا بر عهده data analyst هاست و برای حل اون باید یک پرسشی که در قالب زبان طبیعی هست رو به یک کوئری SQL ای تبدیل کنن. به این تسک در لیترچر هوش مصنوعی، Text to SQL گفته می‌شه. حالا لینکدین طی بلاگی نوشته که چه طور یک محصول AI ای برای Text to SQL برای شرکت خودشون درست کردند. مساله‌شون رو به صورت کلی این شکلی توضیح دادن که یک سری تیبل و دیتا داریم می‌خوایم یک سری سوال بپرسیم که پاسخش، کوئری روی این داده‌هاست. مسیری که ازش باید بگذریم اینه که با توجه به پرسش مطرح شده، جدول‌های مربوط بهش رو پیدا کنیم، روشون کوئری بزنیم و در صورت نیاز اصلاحشون کنیم و همچنین حواسمون باشه که یوزری که داره اون کوئری رو می‌زنه پرمیشن دسترسی به اون جدول‌ها رو داشته باشه.

حالا نحوه حل کردن مساله از RAG می‌گذره و اینها هم به صورت RAG فرمولش کردند. برای این که بتونن RAG بزنن اولا تیم‌ها رو مجبور کردند که جدول‌های مهم و اسکیماشون رو مشخص کنند و برای تیبل‌ها و فیلدها توضیحات بنویسند. بعد این توضیحات رو دادن خود AI هم بر حسب داکیومنتیشن‌های موجود و صحبت‌های تو اسلک تکمیلشون کنه. بعدش هم EBR زدند و ۲۰ تا جدول رو به عنوان مرتبط ترین‌ها با کوئری برگردوندند.

در مرحله بعدی حالا اومدن از خروجی مرحله قبلی استفاده کردند و سعی کردند تیبل‌های محدودتر ولی درست‌تری رو فیلتر کنند. برای این کار اولا اومدند از روی یوزر‌ها و تیبل‌ها و فیلد‌ها نالج گراف ساختند. یوزر این که به چه تیبل‌هایی دسترسی داره و تاریخچه تیبل گردیش چه شکلی بوده و تیبل‌ها هم این که هر تیبل چه فیچر‌هایی داره و یک سری کوئری مرتبط مثالی باهاش و فیلدها هم این که هر فیلد چه توضیحاتی داره و مثلا مقادیر top-k اش چه بودند و اینها. من به شخصه خیلی از این قسمت کارشون خوشم اومد. به نظرم جالب بود. بعد کوئری رو به همراه این نالچ گراف و ۲۰ تا تیبلی که فاز قبلی درآورده بودند دادند دست LLM و ازش خواستند ۷ تا تیبل مرتبط‌تر رو رنک کرد. در مرحله بعدی هم اومدند همین بلا رو سر فیلد‌های این ۷ تیبل درآوردند و فیلدها رو هم محدود کردند. 

حالا موقع ساختن کوئریه. برای این کار یک فرآیند iterative داشتند. به این صورت که LLM میاد از روی متن پرسش و تیبل‌ها و فیلد‌ها، یک پلن می‌نویسه و بعد برای هر مرحله از پلنش، گام به گام یک کوئری می‌نویسه (یعنی CoT زده). بعدش هر مرحله رو ران می‌کنن و خروجی رو براش یک مجموعه validator گذاشتند تا چک کنه آیا این کوئری درست و مربوط هست یا نه. در اینجا باز یک LLM دیگه گذاشتند که به نتایج و کوئری نگاه می‌کنه و در صورتی که تشخیص بده اشتباهی رخ داده، اون رو ارزیابی می‌کنه و درستش می‌کنه. (به حجم مهندسی کار دقت کنید).

این جا تقریبا راه‌حل کلی تمومه. اومدند راجع به این توضیح دادند که روی user experience کار خیلی دقت و تمرکز گذاشتند و تجربه کاربری رو خیلی راحت کردند تا ملت بتونن ازش استفاده کنند. نسخه اولیه‌ محصولشون فقط کوئری SQL می‌نوشته، بعد فهمیدن که کاربرانشون ممکنه نیازهای دیگه‌ای هم داشته باشند، مثلا بخواد راجع به خود table و این که چی هست سوال بپرسه. برای همین یک ماژول intent detection هم باز طراحی کردند و گذاشتند که وظیفه‌اش تشخیص intent کاربر و هدایت اون به مسیر درسته. 

در اخر اذعان کردند که این راه حل خیلی هایپرپارامتر داره و قطعا نیاز هست که بنچمارک و کنترل بشه. برای این کار یک سری معیار تعریف کردند نظیر ریکال تیبل و فیلد، میزان هالوسینیشن مدل روی تیبل‌ها و فیلدها، ارورر سینتکسی، لیتنسی و ...  و مدل رو کنترل کردند. برای جاج مدل هم از عوامل انسانی و باز یک LLM در حکم داور استفاده کردند. این شکلی که با یک عده ground truth اولیه شروع کردند و جواب مدل‌ رو چک ‌می‌کنند. این وسط فهمیدند که یک پرسش ممکنه چندین نوع راه حل و جواب داشته باشه و به کمک همین عوامل انسانی هر سری راه‌حل‌های درست برای یک پرسش رو به مجموعه ground truth شون اضافه می‌کنند و این جوری در طول زمان یک مجموعه برای کنترل کیفیت محصولشون داره. 

درسی که می‌گیریم اینه که ما می‌گیم RAG ولی در عمل هزار پیچش و نکته و ریزه‌کاری مهندسی هست که از RAG یک محصول خفن می‌سازه. فلذا اگر روی مساله‌ای دارید کار می‌کنید و سعی دارید با llm حلش کنید ولی به جواب جذابی نمی‌رسید شاید خیلی ساده‌ دارید مدلش می‌کنید.

لینک بلاگ اصلی:
https://www.linkedin.com/blog/engineering/ai/practical-text-to-sql-for-data-analytics  

لینک این مطلب (کانال تلگرام https://t.me/out_of_distribution):
https://t.me/out_of_distribution/1122
